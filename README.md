# Sonar

Sonar — прототип ассистивного мобильного приложения на Flutter для людей с
нарушением зрения. Приложение получает кадры с камеры, распознает ближайшие
объекты и озвучивает короткие пространственные подсказки с тактильной
обратной связью.

## Важно о безопасности

Это прототип, и он может ошибаться.
Не используйте приложение как единственное средство навигации.
Всегда применяйте белую трость и соблюдайте правила безопасного передвижения.

## Основные возможности

- Поток с камеры в реальном времени с троттлингом обработки кадров.
- Локальная детекция объектов на Android через EfficientDet Lite0.
- Автоматический fallback на базовый ML Kit детектор при сбое локальной модели.
- Пространственная интерпретация объектов:
  - Направление: слева, по центру, справа.
  - Оценка дистанции: рядом, вплотную.
- Голосовые уведомления (`flutter_tts`, `ru-RU`) с защитой от повторного спама.
- Вибро-сигналы (`vibration`) для информационных и срочных событий.
- Жесты на экране камеры:
  - Двойной тап: переключение режима тишины.
  - Долгое нажатие: голосовая сводка по текущей сцене.
- Сохранение принятия рисков и режимов доступности через `shared_preferences`.

## Технологии

- Flutter (Dart 3)
- Управление состоянием: `flutter_riverpod` + генерация кода (`riverpod_annotation`)
- Камера: `camera`
- Компьютерное зрение:
  - `tflite_flutter` (локальная модель EfficientDet Lite0)
  - `google_mlkit_object_detection` (резервный путь)
- Аудио/тактильный вывод:
  - `flutter_tts`
  - `vibration`
- Вспомогательные пакеты:
  - `permission_handler`
  - `shared_preferences`
  - `wakelock_plus`
  - `path_provider`

## Обзор архитектуры

Код в `lib/` разделен по фичам и зонам ответственности:

- `lib/core/`
  - Константы и общие сервисы (TTS, вибрация, настройки, accessibility-режимы).
- `lib/features/safety/`
  - Стартовый экран предупреждения и принятия рисков.
- `lib/features/vision/domain/`
  - Сущности и чистая логика (`SimpleObject`, spatial-вычисления, post-processing).
- `lib/features/vision/services/`
  - Камера, пайплайны детекции, isolate-воркеры, загрузка модели.
- `lib/features/vision/presentation/`
  - UI камеры и слой взаимодействия с пользователем.

### Производительность

- Камера запускается с `ResolutionPreset.medium`, кадры обрабатываются с
  троттлингом (~500 мс).
- Конвертация YUV выполняется вне UI-потока через `compute(...)`.
- Inference EfficientDet выполняется в отдельном isolate
  (`tflite_isolate_worker.dart`).
- Управление вспышкой основано на легковесной оценке яркости и гистерезисе.

## Структура проекта

```text
lib/
  core/
    constants/
    services/
  features/
    safety/presentation/
    vision/
      domain/
      presentation/
      services/
assets/
  models/
    efficientdet_lite0.tflite
    coco_labels_en.txt
test/
```

## Быстрый старт

### Требования

- Установленный и настроенный Flutter SDK.
- Android Studio / Android SDK.
- Для проверки камеры и TFLite рекомендуется физическое Android-устройство.

### Установка зависимостей

```bash
flutter pub get
```

### Генерация файлов Riverpod

```bash
flutter pub run build_runner build --delete-conflicting-outputs
```

### Запуск тестов

```bash
flutter test
```

### Запуск приложения

```bash
flutter run
```

## Разрешения платформ

### Android

Проект запрашивает доступ к камере во время выполнения. Убедитесь, что в
`android/app/src/main/AndroidManifest.xml` есть разрешение:

```xml
<uses-permission android:name="android.permission.CAMERA" />
```

### iOS

Для iOS убедитесь, что в `ios/Runner/Info.plist` добавлено:

```xml
<key>NSCameraUsageDescription</key>
<string>Для обнаружения ближайших объектов требуется доступ к камере.</string>
```

## Текущие ограничения

- Это прототип; качество детекции зависит от сцены и освещения.
- Голосовые подсказки сейчас ориентированы в первую очередь на русский язык.
- Оценка дистанции грубая (`рядом` / `вплотную`) и основана на площади бокса.
- Часть сервисов (например, поток событий кнопок громкости) оставлена как
  основа для дальнейшего расширения.

## Рекомендации для контрибьюторов

- Не выполняйте тяжелую обработку кадров и пиксельные операции в UI-потоке.
- Сохраняйте accessibility-`Semantics` в пользовательских виджетах.
- Выносите бизнес-логику в `domain`/`services` и поддерживайте покрытие тестами.
